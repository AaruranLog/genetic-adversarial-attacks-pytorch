{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "genattack-class.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG455G4yeiJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions.categorical import Categorical\n",
        "from scipy.special import softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPHYcdrGlK_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyajHuui4BiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def is_attack(model, data, t):\n",
        "  \"\"\"\n",
        "  Inputs\n",
        "  model: the PyTorch NN model\n",
        "  data: pertubation + original sample\n",
        "  t: true class label\n",
        "  Output\n",
        "  adv_attack: Whether the new sample is an adversarial attack\n",
        "  \"\"\"\n",
        "  adv_attack = False\n",
        "  model.eval()\n",
        "  t_out = model(data)\n",
        "  t_pred = t_out.argmax(dim=1, keepdim=True)\n",
        "  if t != t_pred:\n",
        "    adv_attack = True\n",
        "\n",
        "  return adv_attack"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8zkAn_dggAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_attack(N, x_orig, t, delta_max, alpha_min, rho_min, G, num_elite, model, fitness_fun, device):\n",
        "    # Algo 1 from : https://arxiv.org/pdf/1805.11090.pdf\n",
        "    #Convergence - best fitness difference within episilon for n generations \n",
        "    #\n",
        "    \"\"\"\n",
        "        N : size of population\n",
        "        x_orig: original example (batch, channel, x, y), batch = 1\n",
        "        t: true label\n",
        "        delta_max: maxmimum distance \n",
        "        alpha_min: min mutation range (~15%)\n",
        "        rho_min: min mutation probability (~10%)\n",
        "        G: # of generations\n",
        "        num_elites: number of top members to keep for the next generation\n",
        "        model: the attacked model\n",
        "        fitness_fun: the objective function used to calculate the fitness\n",
        "        device: hardware the tensors will be stored on\n",
        "    \"\"\"\n",
        "    # initialize population\n",
        "    dims = list(x_orig.size())\n",
        "    dims[0] = N\n",
        "    # population is an (N, 1, 28, 28) in the case of MNIST\n",
        "    population = torch.empty(dims, device=device).uniform_(-delta_max, delta_max)\n",
        "    population = torch.clamp(population + x_orig, 0, 1) - x_orig\n",
        "\n",
        "    #initialize varaibles used in while loop\n",
        "    count = 1          #Start with an intial population - so count starts as 1\n",
        "    crit = 1e-5\n",
        "    adv_attack = last_best = num_i = num_plat = 0\n",
        "\n",
        "    #Continue until max num. of iterations or get an adversarial example\n",
        "    while adv_attack != True and count < G:\n",
        "      if count % 100 == 0:\n",
        "        print(\"Generation \" + str(count))\n",
        "      # Find fitness for every individual and save the best fitness\n",
        "      fitness = fitness_fun(model, population + x_orig, t)\n",
        "      best_fit = min(fitness)\n",
        "\n",
        "      #Check to if fitness last two generations is the same, update num_plat\n",
        "      if abs(best_fit - last_best) <= crit:\n",
        "        num_i += 1\n",
        "        if num_i % 100 == 0 and num_i != 0:\n",
        "          print(\"Plateau at Generation \" + str(count))\n",
        "          num_plat += 1\n",
        "      else:\n",
        "        num_i = 0\n",
        "\n",
        "      # TODO: This block sorts the population by fitness,\n",
        "      # can we use this:\n",
        "      # new_pop = population.clone()[sorted_inds]\n",
        "      # or\n",
        "      # new_pop = population.clone()[fitness.argsort()]\n",
        "      \n",
        "      # TODO: we can use sorted_inds = fitness.argsort() instead for simplicity\n",
        "      # Get sorted indices (Ascending!)\n",
        "      _, sorted_inds = fitness.sort() \n",
        "      #Initialize new population by adding the elites\n",
        "      new_pop = torch.zeros_like(population)\n",
        "      for i in range(num_elite):\n",
        "          new_pop[i] = population[sorted_inds[i]]\n",
        "      \n",
        "      #The best individual is the one with the best fitness\n",
        "      best = new_pop[0]\n",
        "      \n",
        "      adv_attack = is_attack(model, best + x_orig, t)\n",
        "      #If not a true adversarial example need to go to next generation\n",
        "      if adv_attack == False:\n",
        "        alpha = max(alpha_min, 0.5 * (0.9 ** num_plat))\n",
        "        rho = max(rho_min, 0.4 * (0.9 ** num_plat))\n",
        "        # Softmax fitnesses\n",
        "        soft_fit = F.softmax(-fitness, dim=0) # Negate fitness since we're trying to minimize\n",
        "        #need to get apply selection and get a new population\n",
        "        child_pop = selection(population, soft_fit, x_orig, count, alpha, rho, delta_max, num_elite)\n",
        "        new_pop[num_elite:] = child_pop\n",
        "        population = new_pop\n",
        "        count += 1\n",
        "        ## Need to retain best fitness\n",
        "        last_best = best_fit\n",
        "\n",
        "    return best, adv_attack, count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_BWm6qxiYQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mutation_op(cur_pop, x_orig, idx, alpha=0.15, rho=0.1, delta_max=0.1):\n",
        "    \"\"\"\n",
        "        cur_pop: the current population\n",
        "        x_orig :  the image we are using for the attack\n",
        "        idx    : an index. useful for debugging\n",
        "        alpha: mutation range\n",
        "        rho: mutation probability\n",
        "        delta_max: maxmimum distance\n",
        "    \"\"\"\n",
        "    step_noise = alpha * delta_max\n",
        "    perturb_noise = torch.empty_like(cur_pop).uniform_(-step_noise, step_noise)\n",
        "    mask = torch.empty_like(cur_pop).bernoulli_(rho)\n",
        "    mutated_pop = perturb_noise * mask + cur_pop\n",
        "    clamped_mutation_pop = torch.clamp(mutated_pop + x_orig, 0, 1) - x_orig\n",
        "    normalized_pop = torch.clamp(clamped_mutation_pop, -delta_max, delta_max)\n",
        "    return normalized_pop\n",
        "\n",
        "# x = torch.FloatTensor(2, 2)\n",
        "# image = torch.FloatTensor(2, 2).uniform_(0, 1)\n",
        "# print(x, image)\n",
        "# mutpop = mutation_op(x, image, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlQzl-d5ty_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fitness(model, batch, target_class):\n",
        "    \"\"\"\n",
        "        model: a pytorch neural network model (takes x to log probability)\n",
        "        batch: a batch of examples\n",
        "        target_class: the class label of x (as an integer)\n",
        "        returns: tensor of fitnesses\n",
        "        This source code is inspired by:\n",
        "        https://github.com/nesl/adversarial_genattack/blob/2304cdc2a49d2c16b9f43821ad8a29d664f334d1/genattack_tf2.py#L39\n",
        "    \"\"\"\n",
        "    # TODO: does it seem wonky to anyone that we are passing in pop + x_orig\n",
        "    # into the fitness? this might be a design flaw of ours\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        log_probs = model(batch)\n",
        "        s = - torch.expm1(log_probs[:, target_class]) # Sum of probabilities, minus target class, might be more numerically stabe\n",
        "        f = log_probs[:, target_class] - torch.log(s)\n",
        "        return torch.clamp(f.flatten(), -1000, 1000) # clamping to avoid the \"all inf\" problem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2Uf-CmD7Bsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def selection(population, soft_fit, data, idx, alpha, rho, delta_max, num_elite = 2):\n",
        "    \"\"\"\n",
        "        Input\n",
        "        population: the population of individuals\n",
        "        soft_fit: the softmax of the fitnesses \n",
        "        data: the input value to find a perturbation for\n",
        "        idx: the generation number we're on - for debugging purposes\n",
        "        alpha: mutation range\n",
        "        rho: mutation probability\n",
        "        num_elite: the number of elites to carry on from the previous generations\n",
        "        Output\n",
        "        mut_child_pop: Returns the mutated population of children\n",
        "    \"\"\"\n",
        "\n",
        "    # Crossover\n",
        "    cdims = list(population.size())\n",
        "    child_pop_size = population.size()[0] - num_elite\n",
        "    cdims[0] = child_pop_size\n",
        "    child_pop = torch.empty(cdims, device=data.device)\n",
        "    # Roulette\n",
        "    roulette = Categorical(probs=soft_fit)\n",
        "    for i in range(child_pop_size):\n",
        "        parent1_idx = roulette.sample()\n",
        "        soft_fit_nop1 = soft_fit.clone() + 0.0001 # Incrementing by epsilon to avoid the \"all zeros\" problem\n",
        "        soft_fit_nop1[parent1_idx] = 0\n",
        "        roulette2 = Categorical(probs=soft_fit_nop1)\n",
        "        parent2_idx = roulette2.sample()\n",
        "        child = crossover(population[parent1_idx], population[parent2_idx], soft_fit[parent1_idx], soft_fit[parent2_idx])\n",
        "        child_pop[i] = child\n",
        "    \n",
        "    # Mutation\n",
        "    mut_child_pop = mutation_op(child_pop, data, idx, alpha, rho, delta_max)\n",
        "\n",
        "    return mut_child_pop\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_85CkBLj9W4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crossover(parent1, parent2, p1, p2):\n",
        "    \"\"\"\n",
        "    Element-wise crossover\n",
        "    parent1: individual in old population\n",
        "    parent2: individual in old population\n",
        "    p1: softmaxed fitness for parent1\n",
        "    p2: softmaxed fitness for parent2\n",
        "    output\n",
        "    child: new individual from mating of parents\n",
        "    \"\"\"\n",
        "    p = p1/(p1 + p2)\n",
        "    mask = torch.empty_like(parent1).bernoulli_(p)\n",
        "    child = mask * parent1 + (1 - mask) * parent2\n",
        "    return child"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMLeJ6KW1UXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}